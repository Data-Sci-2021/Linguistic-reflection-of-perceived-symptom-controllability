---
title: "SD controllability Analysis"
author: "Yan Wang"
date: "11/02/2021"
output: 
  github_document:
    toc: true
    number_sections: true
---

**This script is a new replacement**

# Load original data sets
```{r setup and load data sets, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(readxl)
library(dplyr)
library(ggplot2)
library(reshape2)
library(lme4)
library(pastecs)
SQR<-read_excel("~/Desktop/DS4Ling-2021/old repository/private/DS4Lingdataset/SQR.xlsx")
OEQ<-read_excel("~/Desktop/DS4Ling-2021/old repository/private/DS4Lingdataset/OEQ- text.xlsx")
Metadata<-read_excel("~/Desktop/DS4Ling-2021/old repository/private/DS4Lingdataset/Metadata of participants.xlsx")
names(SQR)
```

# Original dataset description

SQR is a data set that contains participants ID, time of controllability assessmen [Administration Number], 3 symptoms [S1, S2, S3] and 3 controllability scores [S1Cont, S2Cont, S3Cont]; OEQ contains ID, symptom names and answers for the three questions: 1. "How does the symptom make you feel and what's the cause?", 2. "How does the symptom affect you?" 3."Have you tried anything? Is it helpful?"; Metadata contains ID and sociodemographics, including age, marrige status, employment, education, race, ethnicity. 

# Data preparation

## Calculate the dependent variable = the difference of symptom controllability scores at baseline and 8 weeks (at the end of the intervention)

```{r Data preparation}
SQR_8<- SQR %>% filter(`Administration Number`== "8 week f/u")
SQR_BL<- SQR %>% filter(`Administration Number`=="Baseline (week 0)")
names(SQR_8)[3:9]<-c("Time", "S1Cont", "S2Cont", "S3Cont" , "S1", "S2", "S3")
names(SQR_BL)[3:9]<-c("Time", "S1Cont", "S2Cont", "S3Cont" , "S1", "S2", "S3")
sum(is.na(SQR_BL$S1Cont))
sum(is.na(SQR_8$S1Cont))
SQR_8BL<-inner_join(SQR_8, SQR_BL, by=c("Participant ID", "GOGID", "S1", "S2", "S3"))
SQR_8BL$S1change<-SQR_8BL$S1Cont.x-SQR_8BL$S1Cont.y
SQR_8BL$S2change<-SQR_8BL$S2Cont.x-SQR_8BL$S2Cont.y
SQR_8BL$S3change<-SQR_8BL$S3Cont.x-SQR_8BL$S3Cont.y
Df1<-SQR_8BL %>% dplyr::select(1,2, 7:9, 11:16)
names(Df1)[1:11]<-c("ID", "GOGID", "S1", "S2", "S3", "BLS1", "BLS2", "BLS3", "8BLS1change","8BLS2change", "8BLS3change" )
```

## Reshape Df1 because we want one patient has multiple entries for symptoms, baseline contrallability scores before the intervention, and controllability scores

```{r Reshape Df1}
Df1_1<-Df1 %>% melt(id.vars = c("ID", "GOGID"), measure.vars =c("S1", "S2", "S3"), variable.name = "SymptomNo", value.name = "Symptom") 
Df1_2<-Df1 %>% melt(id.vars = c("ID", "GOGID"), measure.vars =c( "8BLS1change", "8BLS2change", "8BLS3change"), variable.name = "toy", value.name = "8BLChange")
Df1_3<-Df1 %>% melt(id.vars = c("ID", "GOGID"), measure.vars =c("BLS1", "BLS2", "BLS3"), variable.name = "toy", value.name = "BSContr")
colnames(Df1_1)
colnames(Df1_2)
colnames(Df1_3)
levels(Df1_2$toy)[1]<-"S1"
levels(Df1_2$toy)[2]<-"S2"
levels(Df1_2$toy)[3]<-"S3"
names(Df1_2)[3]<-"SymptomNo"
levels(Df1_3$toy)[1]<-"S1"
levels(Df1_3$toy)[2]<-"S2"
levels(Df1_3$toy)[3]<-"S3"
names(Df1_3)[3]<-"SymptomNo"
Df1_4<- inner_join(Df1_1, Df1_2, by= c("ID", "GOGID", "SymptomNo")) %>% inner_join(., Df1_3, by= c("ID", "GOGID", "SymptomNo")) %>% na.omit()
```

## Merge with OEQ (text data) by Participant ID and Symptom
```{r Add text data}
names(OEQ)[1:2]<-c("ID", "Symptom")
Df8BL<-left_join(Df1_4,OEQ, by=c("ID", "Symptom")) %>% na.omit()
names(Df8BL)[7:9]<-c("FeelingCause", "Effect", "Strategy")
```

# Descriptive stats of the controllability score changes from baseline to 8 wks

## Distribution - normality assumed
```{r The dx of controllability score changes }
ggplot(Df8BL)+ 
  geom_histogram(binwidth=0.05, color="blue",aes(x=`8BLChange`, y=..density.., fill=..count..))+ 
  stat_function(fun=dnorm,color="blue",
                args=list(mean=mean(Df8BL$`8BLChange`),sd=sd(Df8BL$`8BLChange`)))
#QQplots
qq<-data.frame(c(Df8BL,qqnorm(Df8BL$`8BLChange`)))
ggplot(qq,aes(x=x,y=y,legend.position="none"))+
  geom_point()+
  geom_smooth(method="lm")+
  labs(title="Q-Q Normal Plot",x="Theoretic",y="Observed")+
  theme_bw()
##boxplots
ggplot(Df8BL)+
  geom_boxplot(aes(Df8BL$`8BLChange`))+
  theme_bw()+
  theme(legend.position="none")
shapiro.test(Df8BL$`8BLChange`)
#install.packages("pastecs")
library(pastecs)
stat.desc(Df8BL$`8BLChange`)
quantile(Df8BL$`8BLChange`, 0.75)-quantile(Df8BL$`8BLChange`, 0.25)
table(Df8BL$`8BLChange`)
```

# Descriptive stats of sample sociodemographic factors
```{r sociodemographic}
table(Metadata$Marriage) %>% addmargins()
table(Metadata$race)%>% addmargins()
table(Metadata$`ethinicity (latio)`)%>% addmargins()
table(Metadata$Employment)%>% addmargins() # 1 is unemployed, 2 is employed, 3 is Unknown
#Age----
stat.desc(Metadata$Age)
quantile(Metadata$Age, 0.75,na.rm = TRUE)-quantile(Metadata$Age, 0.25, na.rm = TRUE)
ggplot(Metadata)+ 
  geom_histogram(binwidth=0.1, color="blue",aes(x=Age, y=..density.., fill=..count..))+ 
  stat_function(fun=dnorm,color="blue",
                args=list(mean=mean(Metadata$Age),sd=sd(Metadata$Age)))
#QQplots
qq<-data.frame(c(Metadata,qqnorm(Metadata$Age)))
ggplot(qq,aes(x=x,y=y,legend.position="none"))+
  geom_point()+
  geom_smooth(method="lm")+
  labs(title="Q-Q Normal Plot",x="Theoretic",y="Observed")+
  theme_bw()
##boxplots
ggplot(Metadata)+
  geom_boxplot(aes(Metadata$Age))+
  theme_bw()+
  theme(legend.position="none")
shapiro.test(Metadata$Age)
#Formal years of education normality is violated-----
stat.desc(Metadata$Formaleducationyears)
quantile(Metadata$Formaleducationyears, 0.75,na.rm = TRUE)-quantile(Metadata$Formaleducationyears, 0.25, na.rm = TRUE)
ggplot(Metadata)+ 
  geom_histogram(binwidth=0.5, color="blue",aes(x=Formaleducationyears, y=..density.., fill=..count..))+ 
  stat_function(fun=dnorm,color="blue",
                args=list(mean=mean(Metadata$Formaleducationyears),sd=sd(Metadata$Formaleducationyears)))
#QQplots
qq<-data.frame(c(Metadata,qqnorm(Metadata$Formaleducationyears)))
ggplot(qq,aes(x=x,y=y,legend.position="none"))+
  geom_point()+
  geom_smooth(method="lm")+
  labs(title="Q-Q Normal Plot",x="Theoretic",y="Observed")+
  theme_bw()
##boxplots
ggplot(Metadata)+
  geom_boxplot(aes(Metadata$Formaleducationyears))+
  theme_bw()+
  theme(legend.position="none")
shapiro.test(Metadata$Formaleducationyears)
```

# Extract linguistics features (predictors) for analysis

I used the software LIWC 2015 (http://liwc.wpengine.com/) to extract multiple existing and 10 self-designed word categories; LightSide (http://ankara.lti.cs.cmu.edu/side/) to tag and calculate frequency of the word "control" as verb and noun, respectively. Existing word categories in LIWC include 4 summary language variables (analytical thinking, clout [confidence], authenticity, and emotional tone), 3 general descriptor categories (words per sentence, percent of target words captured by the dictionary, and percent of words in the text that are longer than six letters), 21 standard linguistic dimensions (e.g., percentage of words in the text that are pronouns, articles, auxiliary verbs, etc.), 41 word categories tapping psychological constructs (e.g., affect, cognition, biological processes, drives), 6 personal concern categories (e.g., work, home, leisure activities), 5 informal language markers (assents, fillers, swear words, netspeak), and 12 punctuation categories (periods, commas, etc). 
I saved all the results in the file "ResultSDWrite8BL.xlsx"

# Load the full dataset (Df) for analysis

```{r Full dataset for analysis}
Df<-read.csv("~/Desktop/DS4Ling-2021/old repository/private/DS4Lingdataset/Results8BLSDWrite.csv")
Df$controlNN[is.na(Df$controlNN)]=0
Df$controlVB[is.na(Df$controlVB)]=0
Df[is.na(Df)]
Df$controlNN<-Df$controlNN/Df$WC*100
Df$controlVB<-Df$controlVB/Df$WC*100
Df<- Df %>% dplyr::select(2, 4:7, 11,106:112, 12:105)
names(Df)
```

# Preliminary bivariate correlation between the dependent variable and potential predictors 
Since ContrChange is dichotimized into 0 and 1, so I use pearson correlation, which yield the same results as biserial correlation test. 
```{r Bivariate correlation}
library(Hmisc)
library(corrgram)
#there is no variation in column #106
Df <- Df[,-106]
res <- cor(Df[4:105])
round(res, 2)[, 1] 
#significant
cor.test(Df$ X8wkContr, Df$symptom)
cor.test(Df$ X8wkContr, Df$WC)
cor.test(Df$ X8wkContr, Df$controlled)
cor.test(Df$ X8wkContr, Df$controlNN)
cor.test(Df$ X8wkContr, Df$anx)
cor.test(Df$ X8wkContr, Df$body)
```

# Model buiding - Mixed-effect regression model

Based on bivariate correlation tests, I have some ideas of candidate predictors. 
Since this analysis is exploratory in nature and we have a lot of potential predictors. I will explore a few approaches of model building

1. Identifying random effect: 1.participant ID; 2. baseline symptom controllability score

2. predictors in the model: 1. purpose-oriented; 2. stepwise selection

## Convenience functions for model comparison

```{r Convenience functions for model comparison}
##Get convergence code for a single model. verbose: TRUE to return full convergence code, FALSE to return logical. checkSingular: TRUE to count singular fit as nonconvergence, FALSE to ignore singular fit-----
getConvCode <- function (x, verbose=FALSE, checkSingular=TRUE) {
  library(lme4)
  library(purrr)
  
  ##Get convergence messages
  convMsg <-
    x %>% 
    attr("optinfo") %>% 
    pluck("conv", "lme4")
  
  ##Get singular-fit status
  if (checkSingular) sgFit <- x %>% isSingular()
  
  ##If not verbose, get convergence code as logical
  if (!verbose) {
    convCode <- length(convMsg)==0
    if (checkSingular) convCode <- convCode & !sgFit
    ##If verbose, get convergence code as character
  } else {
    convCode <- character(0L)
    if (length(convMsg) > 0) {
      convCode <- convMsg %>% 
        pluck("messages") %>% 
        paste(collapse="\n")
    }
    
    if (checkSingular) {
      if (sgFit) {
        convCode <- paste(c(convCode, "Singular fit"), collapse="\n")
      }
    }
    
    ##If nothing has been added to convCode, return the good news.
    if (length(convCode)==0) {
      convCode <- "Converged"
      if (checkSingular) convCode <- paste0(convCode, ", no singular fit")
    }
  }
  
  convCode
}

##Convenience function for checking if something is an error
is.error <- function(x) "error" %in% class(x)

##Get Fox & Monette's (1992) GVIF, which is the square of the "GVIF" reported
##  by car::vif() and thus is comparable to the 'VIF < 10' criterion.
##Whereas car::vif() returns either a vector or a matrix, this function always
##  returns a dataframe
vif <- function(mod, decreasing=TRUE) {
  library(car)
  library(dplyr)
  
  vifReturn <- tryCatch(car::vif(mod),
                        ##Catch and return "fewer than 2 terms" error"
                        error = function(e) e)
  
  if (is.error(vifReturn)) {
    return(NA)
  }
  ##Turn vector VIF into dataframe
  if (is.numeric(vifReturn) & !is.matrix(vifReturn)) {
    ret <- data.frame(Term = names(vifReturn),
                      GVIF = vifReturn,
                      Df = rep(1, length(vifReturn))) %>% 
      mutate(`GVIF^(1/(2*Df))` = sqrt(vifReturn),
             `GVIF^(1/Df)` = vifReturn)
  }
  ##Turn matrix VIF into dataframe
  if (is.numeric(vifReturn) & is.matrix(vifReturn)) {
    ret <- as.data.frame(vifReturn) %>% 
      rownames_to_column("Term") %>% 
      select(Term, everything()) %>% 
      mutate(`GVIF^(1/Df)` = GVIF ^ (1/Df))
  }
  
  ret
}

##Get maximum VIF from model
getMaxVIF <- function(mod, decreasing=TRUE) {
  library(dplyr)
  library(purrr)
  
  ##If just one term, return NA
  if (length(labels(terms(mod))) < 2) 
    return(NA)
  
  vif(mod) %>% 
    ##Get unique max GVIF (in case there are ties)
    arrange(desc(`GVIF^(1/Df)`)) %>% 
    slice(1) %>% 
    pull(`GVIF^(1/Df)`, name=Term)
}
```

## Use participant ID as random effect and select predictors with purpose. Since baseline controllability score is highly correlated with the changes, I will also block this variable as a random effect.

```{r ID and baseline controllability as random effects}
#allfit function-----
library(optimx)
library(dfoptim)
allFit <- system.file("utils", "allFit.R", package="lme4")
file.show(allFit)
## WC, symptom, controlled, controlNN, anx, body 
toy1<-lmer( X8wkContr ~ symptom+(1|ID)+(1|BSContr),Df)
summary(toy1)

toy2<-lmer( X8wkContr ~ symptom+WC+(1|ID)+(1|BSContr),Df)
summary(toy2)
anova(toy2, toy1)

toy3<-lmer( X8wkContr ~ symptom+WC+ anx+(1|ID)+(1|BSContr),Df)
summary(toy3)
anova(toy3, toy2)

toy4<-lmer( X8wkContr ~ symptom+WC+ anx+ body+(1|ID)+(1|BSContr),Df)
summary(toy4)
anova(toy4, toy3)
vif(toy4)
```


```{r}
sessionInfo()
```



